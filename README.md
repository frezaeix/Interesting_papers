# Interesting_papers
Summary of some interesting ML/CV papers

## [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale, ICLR'21](https://arxiv.org/pdf/2010.11929)
* "Transformers lack some of the inductive biases inherent to CNNs, such as translation equivariance and locality, and therefore do not generalize well when trained on insufficient amounts of data. However, the picture changes if the models are trained on larger datasets (14M-300M images). We f ind that large scale training trumps inductive bias. Our Vision Transformer (ViT) attains excellent results when pre-trained at sufficient scale and transferred to tasks with fewer datapoints."
* 

![image](https://user-images.githubusercontent.com/13063395/147115474-a2f9919b-54ec-4a18-8f93-e7d196124b3d.png)


## [Attention Is All You Need, Neurips'17](https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)
* https://towardsdatascience.com/attention-is-all-you-need-discovering-the-transformer-paper-73e5ff5e0634
